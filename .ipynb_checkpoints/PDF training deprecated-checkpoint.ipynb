{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, h5py, torch, copy, time, datetime\n",
    "from torch import nn\n",
    "from tabulate import tabulate\n",
    "from torch.nn.modules import Module\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "####### Loss function(s), with \"input\" in (0,1) interval\n",
    "class _Loss(Module):\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='mean'):\n",
    "        super(_Loss, self).__init__()\n",
    "        if size_average is not None or reduce is not None:\n",
    "            self.reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
    "        else:\n",
    "            self.reduction = reduction\n",
    "            \n",
    "class WeightedSELoss(_Loss):\n",
    "    __constants__ = ['reduction']\n",
    "        \n",
    "    def __init__(self, size_average=None, reduce=None, reduction='mean'):\n",
    "        super(WeightedSELoss, self).__init__(size_average, reduce, reduction)\n",
    "    def forward(self, input, target, weight):\n",
    "        return torch.sum(torch.mul(weight, (input - target)**2))\n",
    "\n",
    "class WeightedCELoss(_Loss):\n",
    "    __constants__ = ['reduction']\n",
    "        \n",
    "    def __init__(self, size_average=None, reduce=None, reduction='mean'):\n",
    "        super(WeightedCELoss, self).__init__(size_average, reduce, reduction)\n",
    "    def forward(self, input, target, weight):\n",
    "        return torch.sum(torch.mul(weight, (1 - target)*torch.log(1./(1.-input))+target*torch.log(1./input)))\n",
    "    \n",
    "####### Loss function(s), with \"input\" in (0,1) interval\n",
    "def report_ETA(beginning, start, epochs, e, loss):\n",
    "    time_elapsed = time.time() - start\n",
    "    time_left    = str(datetime.timedelta(\n",
    "        seconds=((time.time() - beginning)/(e+1)*(epochs-(e+1)))))\n",
    "    print('Training epoch %s (took %.2f sec, time left %s sec) loss %.8f'%(\n",
    "        e, time_elapsed, time_left, loss))\n",
    "    return time.time()\n",
    "\n",
    "class DataFile():\n",
    "### Reads sample file Info (string), Parameters (list), Values (torch array), Data (torch array) and Weights (torch array)\n",
    "### FilePath is the path of the input file\n",
    "### Computes cross-section XS (average weight) and total number of data ND in file\n",
    "### Checks that files are in correct format (correct Keys)\n",
    "### and that the length of Parameters and Data equals the one of Values and Weights respectively\n",
    "    def __init__(self, FilePath, verbose=True):\n",
    "        if verbose: print('\\nReading file ...' + FilePath)\n",
    "        file = h5py.File(FilePath, 'r')\n",
    "        if list(file.keys()) == ['Data', 'Info', 'PDF_weights', 'Parameters', 'Process', 'Values', 'Weights']:\n",
    "            if( (len(file['Parameters'][()]) == len(file['Values'][()])) and (len(file['Data'][()]) == len(file['Weights'][()])) ):\n",
    "                if verbose: print('##### File Info:\\n' + file['Info'][()][0] + '\\n#####')\n",
    "                self.FilePath = FilePath\n",
    "                self.Info = file['Info'][()][0]\n",
    "                self.Process = file['Process'][()][0]\n",
    "                self.Parameters = file['Parameters'][()]\n",
    "                self.Values = torch.DoubleTensor(file['Values'][()])\n",
    "                self.Data = torch.DoubleTensor(file['Data'][()])\n",
    "                self.PDFWeights = torch.DoubleTensor(file['PDF_weights'][()])\n",
    "                self.Weights = torch.DoubleTensor(file['Weights'][()])\n",
    "                self.XS = self.Weights.mean()\n",
    "                self.ND = self.Data.size(0)\n",
    "            else: \n",
    "                print('--> File not valid:\\nunequal lenght of Values and Parameters or of Data and Weights')\n",
    "                raise ValueError\n",
    "        else:\n",
    "            print('--> File format not valid:\\nKeys: ' + str(list(file.keys())) + \n",
    "                  '\\nshould be: ' + str(['Data', 'Info', 'PDF_weights', 'Parameters', 'Process', 'Values', 'Weights']))\n",
    "            raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OurCudaTensor(input):\n",
    "    output = copy.deepcopy(input)\n",
    "    output = output.cuda()\n",
    "    return output\n",
    "\n",
    "class OurTrainer(nn.Module):\n",
    "### Contains all parameters for training: Loss Function, Optimiser, NumberOfEpochs, InitialLearningRate, SaveAfterEpoch \n",
    "    def __init__(self, LearningRate = 1e-3, LossFunction = 'Quadratic', Optimiser = 'Adam', NumEpochs = 100):\n",
    "        super(OurTrainer, self).__init__() \n",
    "        self.NumberOfEpochs = NumEpochs\n",
    "        self.SaveAfterEpoch = lambda :[self.NumberOfEpochs,]\n",
    "        self.InitialLearningRate = LearningRate\n",
    "        ValidCriteria = {'Quadratic': WeightedSELoss(), 'CE':WeightedCELoss()}\n",
    "        try:\n",
    "            self.Criterion = ValidCriteria[LossFunction]\n",
    "        except KeyError:\n",
    "            print('The loss function specified is not valid. Allowed losses are %s.'\n",
    "                 %str(list(ValidCriteria)))\n",
    "            print('Will use Quadratic Loss.') \n",
    "        ValidOptimizers = {'Adam': torch.optim.Adam}\n",
    "        try:\n",
    "            self.Optimiser =  ValidOptimizers[Optimiser]\n",
    "        except KeyError:\n",
    "            print('The specified optimiser is not valid. Allowed optimisers are %s.'\n",
    "                 %str(list(ValidOptimisers)))\n",
    "            print('Will use Adam.')          \n",
    "    \n",
    "    def EstimateRequiredGPUMemory(self, model, Data, Parameters):\n",
    "        if next(model.parameters()).is_cuda:\n",
    "            print('Model is on cuda. No estimate possible anymore.')\n",
    "            return None\n",
    "        else:\n",
    "            before = torch.cuda.memory_allocated()\n",
    "            print(before)\n",
    "            ### Always make deep copy of objects before sending them to cuda. Delete when done\n",
    "            ModelCuda = copy.deepcopy(model)\n",
    "            ModelCuda.cuda()\n",
    "            DataCuda = OurCudaTensor(Data[:10000])\n",
    "            ParametersCuda = OurCudaTensor(Parameters[:10000])\n",
    "            print(torch.cuda.memory_allocated())\n",
    "            MF = ModelCuda.Forward(DataCuda, ParametersCuda)\n",
    "            after = torch.cuda.memory_allocated()\n",
    "            print(after)\n",
    "            del ModelCuda, DataCuda, ParametersCuda, MF\n",
    "            torch.cuda.empty_cache()        \n",
    "            estimate = float(Data.size()[0])/1e4*float(after-before)*1e-9\n",
    "            print(str(estimate) + ' GB')\n",
    "            return estimate\n",
    "        \n",
    "    def Train(self, model, Data, PDFWeights, Labels, Weights, bs = 100000, L1perUnit=None, UseGPU=True, Name=\"\", Folder=os.getcwd(), WeightClipping=False, L1Max=1):\n",
    "        tempmodel = copy.deepcopy(model)\n",
    "        tempmodel.cuda()\n",
    "        tempData = OurCudaTensor(Data)\n",
    "        tempPDFWeights = OurCudaTensor(PDFWeights)\n",
    "        tempLabels = OurCudaTensor(Labels)\n",
    "        tempWeights = OurCudaTensor(Weights)\n",
    "        \n",
    "        Optimiser = self.Optimiser(tempmodel.parameters(), self.InitialLearningRate)\n",
    "        mini_batch_size = bs\n",
    "        beginning = start = time.time()\n",
    "        \n",
    "        if WeightClipping:\n",
    "            tempmodel.GetL1Bound(L1Max)\n",
    "        \n",
    "        for e in range(self.NumberOfEpochs):\n",
    "            total_loss  = 0\n",
    "            #print(\"epoch\")\n",
    "            Optimiser.zero_grad()\n",
    "            for b in range(0, Data.size(0), mini_batch_size):\n",
    "                torch.cuda.empty_cache()\n",
    "                output          = tempmodel.Forward(tempData[b:b+mini_batch_size], tempWeights[b:b+mini_batch_size])\n",
    "                loss            = self.Criterion(output, tempLabels[b:b+mini_batch_size].reshape(-1,1), \n",
    "                                                tempPDFWeights[b:b+mini_batch_size].reshape(-1, 1))\n",
    "                total_loss += loss\n",
    "                loss.backward()\n",
    "            Optimiser.step()\n",
    "            \n",
    "            if WeightClipping:\n",
    "                tempmodel.ClipL1Norm()\n",
    "            \n",
    "            if (e+1) in self.SaveAfterEpoch():\n",
    "                start       = report_ETA(beginning, start, self.NumberOfEpochs, e+1, total_loss)\n",
    "                tempmodel.Save(Name + \"%d epoch\"%(e+1), Folder, csvFormat=True)\n",
    "        \n",
    "        tempmodel.Save(Name + 'Final', Folder, csvFormat=True)\n",
    "        \n",
    "        return tempmodel.cpu()\n",
    "    \n",
    "    def SetNumberOfEpochs(self, NE):\n",
    "        self.NumberOfEpochs = NE\n",
    "        \n",
    "    def SetInitialLearningRate(self,ILR):\n",
    "        self.InitialLearningRate = ILR\n",
    "        \n",
    "    def SetSaveAfterEpochs(self,SAE):\n",
    "        SAE.sort()\n",
    "        self.SaveAfterEpoch = lambda : SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurTrainingData():\n",
    "### Imports data for training. The Return() methods returns [self.Data, self.Labels, self.Weights, self.ParVal]\n",
    "### All values are in double precision\n",
    "### Inputs are the SM and BSM file paths and list of integers to chop the datasets if needed\n",
    "### Weights are normalized to have sum = 1 on the entire training sample\n",
    "    def __init__(self, SMfilepathlist, BSMfilepathlist, process, parameters, SMNLimits=\"NA\", BSMNLimits=\"NA\", verbose=True): \n",
    "        self.Process = process\n",
    "        self.Parameters = parameters\n",
    "        self.BSMfilepathlist = BSMfilepathlist\n",
    "        self.SMfilepathlist = SMfilepathlist\n",
    "        if verbose: print('Loading Data Files for Process: ' + str(self.Process) +', with new physics Parameters: ' + str(self.Parameters) ) \n",
    "        #if len(self.Parameters)!= 1: print('Only 1D Implemented in Training !')   \n",
    "                \n",
    "####### Load BSM data (stored in self.BSMDataFiles)\n",
    "        if (not BSMfilepathlist):\n",
    "            # When studying nuisance parameters, BSM data can optional\n",
    "            print('No BSM files input. Skipping loading BSM files.')\n",
    "        elif type(BSMfilepathlist) == list:\n",
    "            if all(isinstance(n, str) for n in BSMfilepathlist):\n",
    "                self.BSMDataFiles = [] \n",
    "                for path in BSMfilepathlist:\n",
    "                    temp =  DataFile(path, verbose=verbose)\n",
    "                    if((temp.Process == self.Process) and (set(list(temp.Parameters.flatten())) == set(self.Parameters)) and (sum(temp.Values.flatten()) != 0.) ):\n",
    "                        self.BSMDataFiles.append(temp)\n",
    "                    else: \n",
    "                        print('File not valid: ' + path)\n",
    "                        print('Parameters = ' + str(temp.Parameters) + ', Process = ' + str(temp.Process) \n",
    "                              +' and Values = ' + str(temp.Values.tolist()))\n",
    "                        print('should be = ' + str(self.Parameters) + ', = ' + str(self.Process) \n",
    "                              + ' and != ' + str(0.))\n",
    "                        raise ValueError\n",
    "                        self.BSMDataFiles.append(None) \n",
    "            else:\n",
    "                print('BSMfilepathlist input should be a list of strings !')\n",
    "                raise FileNotFoundError\n",
    "        else:\n",
    "            print('BSMfilepathlist input should be a list !')\n",
    "            raise FileNotFoundError\n",
    "                  \n",
    "###### Chop the BSM data sets (stored in BSMNDList, BSMDataList, BSMWeightsList, BSMParValList, BSMTargetList)\n",
    "        if not BSMfilepathlist:\n",
    "            # When studying nuisance parameters, BSM data can optional.\n",
    "            # Here there is simply no BSM data to chop\n",
    "            print('No BSM files input. Skipping loading BSM data.')\n",
    "        else:\n",
    "            if type(BSMNLimits) == int:\n",
    "                BSMNLimits = [min(BSMNLimits, NF.ND) for NF in self.BSMDataFiles]\n",
    "            elif type(BSMNLimits) == list and all(isinstance(n, int) for n in BSMNLimits):\n",
    "                if len(BSMNLimits) != len(self.BSMDataFiles):\n",
    "                    print(\"--> Please input %d integers to chop each SM file.\"%(\n",
    "                        len(self.BSMDataFiles)))\n",
    "                    raise ValueError\n",
    "                elif sum([self.BSMDataFiles[i].ND >= BSMNLimits[i] for i in range(len(BSMNLimits))]\n",
    "                        ) != len(self.BSMDataFiles):\n",
    "                    print(\"--> Some chop limit larger than available data in the corresponding file.\")\n",
    "                    print(\"--> Lengths of the files: \"+str([file.ND for file in self.BSMDataFiles ]))\n",
    "                    raise ValueError\n",
    "            else:\n",
    "                BSMNLimits =[file.ND for file in self.BSMDataFiles]   \n",
    "\n",
    "            self.BSMNDList = BSMNLimits\n",
    "            #self.BSMNData = sum(self.BSMNDataList)\n",
    "            self.BSMDataList = [DF.Data[:N] for (DF, N) in zip(\n",
    "                self.BSMDataFiles, self.BSMNDList)]\n",
    "            self.BSMPDFWeightsList = [DF.PDFWeights[:N] for (DF, N) in zip(\n",
    "                self.BSMDataFiles, self.BSMNDList)] \n",
    "            self.BSMWeightsList = [DF.Weights[:N] for (DF, N) in zip(\n",
    "                self.BSMDataFiles, self.BSMNDList)] \n",
    "            self.BSMXSList = [DF.XS for DF in self.BSMDataFiles]\n",
    "            self.BSMParValList =  [torch.ones([N, len(self.Parameters)], dtype=torch.double)*DF.Values for (DF, N) in zip(self.BSMDataFiles, self.BSMNDList)]\n",
    "            self.BSMTargetList = [torch.ones(N, dtype=torch.double) for N in self.BSMNDList] \n",
    "\n",
    "\n",
    "####### Load SM data (stored in SMDataFiles)\n",
    "        if not SMfilepathlist:\n",
    "            # When studying nuisance parameters, SM data can be optional\n",
    "            print('No SM files input. Skipping loading SM files.')\n",
    "        elif type(SMfilepathlist) == list:\n",
    "            if all(isinstance(n, str) for n in SMfilepathlist):\n",
    "                #self.SMFilePathList = SMfilepathlist\n",
    "                #self.SMNumFiles = len(self.SMFilePathList)\n",
    "                self.SMDataFiles = []\n",
    "                for path in SMfilepathlist:\n",
    "                    temp =  DataFile(path, verbose=verbose)\n",
    "                    if( (temp.Process == self.Process) and (temp.Parameters[0] == 'SM') and (sum(temp.Values.flatten()) == 0.) ):\n",
    "                        self.SMDataFiles.append(temp)\n",
    "                    else:\n",
    "                        print('File not valid: ' + path)\n",
    "                        print('Parameters = ' + str(temp.Parameters) + ', Process = ' + str(temp.Process) \n",
    "                              +' and Values = ' + str(temp.Values.tolist()))\n",
    "                        print('should be = ' + 'SM'+ ', = ' + str(self.Process) \n",
    "                              + ' and = ' + str(0.))\n",
    "                        self.SMDataFiles.append(None)                    \n",
    "            else:\n",
    "                print('SMfilepathlist input should be a list of strings !')\n",
    "                raise FileNotFoundError\n",
    "        else:\n",
    "            print('SMfilepathlist input should be a list !')\n",
    "            raise FileNotFoundError\n",
    "            \n",
    "####### Chop the SM data sets and join them in one (stored in SMND, SMData and SMWeights)\n",
    "        if not SMfilepathlist:\n",
    "            # When studying nuisance parameters, BSM data can optional.\n",
    "            # Here there is simply no BSM data to chop\n",
    "            print('No SM files input. Skipping loading SM data.')\n",
    "        else:\n",
    "            if type(SMNLimits) == int:\n",
    "                SMNLimits = [min(SMNLimits, DF.ND) for DF in self.SMDataFiles]\n",
    "            elif type(SMNLimits) == list and all(isinstance(n, int) for n in SMNLimits):\n",
    "                if len(SMNLimits) != len(self.SMDataFiles):\n",
    "                    print(\"--> Please input %d integers to chop each SM file.\"%(\n",
    "                        len(self.SMDataFiles)))\n",
    "                    raise ValueError\n",
    "                elif sum([self.SMDataFiles[i].ND >= SMNLimits[i] for i in range(len(SMNLimits))]\n",
    "                        ) != len(self.SMDataFiles):\n",
    "                    print(\"--> Some chop limit larger than available data in the corresponding file.\")\n",
    "                    print(\"--> Lengths of the files: \" + str([file.ND for file in self.SMDataFiles]))\n",
    "                    raise ValueError\n",
    "            else:\n",
    "                SMNLimits = [file.ND for file in self.SMDataFiles]\n",
    "            self.SMND = sum(SMNLimits)\n",
    "            self.SMData = torch.cat(\n",
    "                [DF.Data[:N] for (DF, N) in zip(self.SMDataFiles, SMNLimits)]\n",
    "                , 0) \n",
    "            self.SMPDFWeights = torch.cat(\n",
    "                [DF.PDFWeights[:N] for (DF, N) in zip(self.SMDataFiles, SMNLimits)]\n",
    "                , 0)\n",
    "            self.SMWeights = torch.cat(\n",
    "                [DF.Weights[:N] for (DF, N) in zip(self.SMDataFiles, SMNLimits)]\n",
    "                , 0)\n",
    "            self.SMXSList = [DF.XS for DF in self.SMDataFiles]\n",
    "\n",
    "        if BSMfilepathlist and SMfilepathlist:\n",
    "            # only SM and BSM data\n",
    "            print(\"With SM and BSM files, breaking SM data blocks to be pared with BSM data.\")\n",
    "    ####### Break SM data in blocks to be paired with BSM data (stored in UsedSMNDList, UsedSMDataList, UsedSMWeightsList, UsedSMParValList, UsedSMTargetList)\n",
    "            BSMNRatioDataList = [torch.tensor(1., dtype=torch.double)*n/sum(self.BSMNDList\n",
    "                                                                           ) for n in self.BSMNDList]\n",
    "            self.UsedSMNDList = [int(self.SMND*BSMNRatioData) for BSMNRatioData in BSMNRatioDataList] \n",
    "            self.UsedSMDataList =  self.SMData[:sum(self.UsedSMNDList)].split(self.UsedSMNDList)\n",
    "            self.UsedSMPDFWeightsList = self.SMPDFWeights[:sum(self.UsedSMNDList)].split(self.UsedSMNDList)\n",
    "\n",
    "        ##### Reweighting is performed such that the SUM of the SM weights in each block equals the number of BSM data times the AVERAGE \n",
    "        ##### of the original weights. This equals the SM cross-section as obtained in the specific sample at hand, times NBSM\n",
    "            self.UsedSMWeightsList = self.SMWeights[:sum(self.UsedSMNDList)].split(self.UsedSMNDList)\n",
    "            self.UsedSMWeightsList = [ self.UsedSMWeightsList[i]*self.BSMNDList[i]/self.UsedSMNDList[i] for i in range(len(BSMNRatioDataList))]   \n",
    "            self.UsedSMParValList =  [torch.ones([N, len(self.Parameters)], dtype=torch.double)*DF.Values for (DF, N) in zip(self.BSMDataFiles, self.UsedSMNDList)]       \n",
    "            self.UsedSMTargetList = [torch.zeros(N, dtype=torch.double) for N in self.UsedSMNDList]\n",
    "\n",
    "    ####### Join SM with BSM data\n",
    "            self.Data = torch.cat(\n",
    "                [torch.cat([self.UsedSMDataList[i], self.BSMDataList[i]]\n",
    "                                      ) for i in range(len(self.BSMDataList))]\n",
    "                )\n",
    "            self.PDFWeights = torch.cat(\n",
    "                [torch.cat([self.UsedSMPDFWeightsList[i], self.BSMPDFWeightsList[i]]\n",
    "                                      ) for i in range(len(self.BSMPDFWeightsList))]\n",
    "                )\n",
    "            self.Weights = torch.cat(\n",
    "                [torch.cat([self.UsedSMWeightsList[i], self.BSMWeightsList[i]]\n",
    "                                      ) for i in range(len(self.BSMWeightsList))]\n",
    "                )\n",
    "            self.Labels = torch.cat(\n",
    "                [torch.cat([self.UsedSMTargetList[i], self.BSMTargetList[i]]\n",
    "                                      ) for i in range(len(self.BSMTargetList))]\n",
    "                )\n",
    "            self.ParVal = torch.cat(\n",
    "                [torch.cat([self.UsedSMParValList[i], self.BSMParValList[i]]\n",
    "                                      ) for i in range(len(self.BSMParValList))]\n",
    "                )\n",
    "        \n",
    "####### Simple assignment\n",
    "        if not BSMfilepathlist:\n",
    "            # only SM data\n",
    "            print('No BSM files input. Simply assign SM data.')\n",
    "            self.Data = self.SMData\n",
    "            self.PDFWeights = self.SMPDFWeights\n",
    "            self.Weights = self.SMWeights\n",
    "            self.Labels = torch.zeros(self.Data.size(0), dtype=torch.double)\n",
    "            self.ParVal = torch.zeros([self.Data.size(0), len(self.Parameters)], dtype=torch.double)\n",
    "        elif not SMfilepathlist:\n",
    "            # only BSM data\n",
    "            print('No SM files input. Simply assign BSM data.')\n",
    "            self.Data = torch.cat(self.BSMDataList)\n",
    "            self.PDFWeights = torch.cat(self.BSMPDFWeightsList)\n",
    "            self.Weights = torch.cat(self.BSMWeightsList)\n",
    "            self.Labels = torch.ones(self.Data.size(0), dtype=torch.double)\n",
    "            self.ParVal = torch.cat(self.BSMParValList)\n",
    "\n",
    "####### Final reweighting\n",
    "        s = self.Weights.sum()\n",
    "        self.Weights = self.Weights.div(s)\n",
    "\n",
    "####### If verbose, display report\n",
    "        if verbose: self.Report()\n",
    "        \n",
    "####### Return Tranining Data\n",
    "    def ReturnData(self):\n",
    "        return [self.Data, self.Labels, self.Weights, self.ParVal]\n",
    "                    \n",
    "    def Report(self):\n",
    "        #from tabulate import tabulate\n",
    "        if self.SMfilepathlist:\n",
    "            print('\\nLoaded SM Files:')\n",
    "            print(tabulate({str(self.Parameters): [ file.Values for file in self.SMDataFiles ], \n",
    "                            \"#Data\":[ file.ND for file in self.SMDataFiles ], \n",
    "                            \"XS[pb](avg.w)\":[ file.XS for file in self.SMDataFiles ]}, headers=\"keys\"))\n",
    "            \n",
    "        if self.BSMfilepathlist:\n",
    "            print('\\nLoaded BSM Files:')\n",
    "            print(tabulate({str(self.Parameters): [ file.Values for file in self.BSMDataFiles ], \n",
    "                            \"#Data\":[ file.ND for file in self.BSMDataFiles ], \n",
    "                            \"XS[pb](avg.w)\":[ file.XS for file in self.BSMDataFiles ]}, headers=\"keys\"))\n",
    "            \n",
    "        if self.SMfilepathlist and self.BSMfilepathlist:\n",
    "            print('\\nPaired BSM/SM Datasets:\\n')\n",
    "            ### Check should be nearly equal to #EV.BSM. It is computed with the weights BEFORE final reweighting\n",
    "            print(tabulate({str(self.Parameters): [ file.Values for file in self.BSMDataFiles ], \"#Ev.BSM\": self.BSMNDList\n",
    "                            , \"#Ev.SM\": self.UsedSMNDList,\n",
    "                            \"Check\": [(self.UsedSMWeightsList[i].sum())/(self.SMWeights.mean()) for i in range(len(self.BSMDataFiles))]\n",
    "                           }, headers=\"keys\"))    \n",
    "        \n",
    "####### Convert Angles\n",
    "    def CurateAngles(self, AnglePos):\n",
    "        Angles = self.Data[:, AnglePos]\n",
    "        CuratedAngles = torch.cat([torch.sin(Angles), torch.cos(Angles)], dim=1)\n",
    "        OtherPos = list(set(range(self.Data.size(1)))-set(AnglePos))\n",
    "        self.Data = torch.cat([self.Data[:, OtherPos], CuratedAngles], dim=1)\n",
    "        print('####\\nAnlges at position %s have been converted to Sin and Cos and put at the last columns of the Data.'%(AnglePos))\n",
    "        print('####')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurLinearModel(nn.Module):\n",
    "### Defines the  model with parametrized discriminant. Only quadratic dependence on a single parameter is implemented.\n",
    "### Input is the architecture (list of integers, the last one being equal to 1) and the activation type ('ReLU' or 'Sigmoid')\n",
    "    def __init__(self, NumberOfNuisanceParameters, AR = [1, 3, 3, 1] , AF = 'ReLU'):               \n",
    "        super(OurLinearModel, self).__init__() \n",
    "        ValidActivationFunctions = {'ReLU': torch.relu, 'Sigmoid': torch.sigmoid}\n",
    "        try:\n",
    "            self.ActivationFunction = ValidActivationFunctions[AF]\n",
    "        except KeyError:\n",
    "            print('The activation function specified is not valid. Allowed activations are %s.'\n",
    "                 %str(list(ValidActivationFunctions.keys())))\n",
    "            print('Will use ReLU.')\n",
    "            self.ActivationFunction = torch.relu            \n",
    "        if type(AR) == list:\n",
    "            if( ( all(isinstance(n, int) for n in AR)) and ( AR[-1] == NumberOfNuisanceParameters) ):\n",
    "                self.Architecture = AR\n",
    "                self.NumberOfNuisanceParameters = NumberOfNuisanceParameters\n",
    "            else:\n",
    "                print('Architecture should be a list of integers, the last one should be equal to # of nuisance.')\n",
    "                raise ValueError             \n",
    "        else:\n",
    "            print('Architecture should be a list !')\n",
    "            raise ValueError\n",
    "        \n",
    "        self.DefineLayers()\n",
    "\n",
    "        \n",
    "### Define Layers. For the linear model, the number of nuisance networks is equal to the number of nuisance parameters\n",
    "    def DefineLayers(self):\n",
    "        LinearLayers = [nn.Linear(self.Architecture[i], self.Architecture[i+1]) \\\n",
    "                                  for i in range(len(self.Architecture)-1)]\n",
    "        self.LinearLayers = nn.ModuleList(LinearLayers)        \n",
    "        \n",
    "### Forward Function. Performs Preprocessing, returns F = rho/(1+rho) in [0,1], where rho is linearly parametrized\n",
    "### by the nuisance parameters.\n",
    "    def Forward(self, Data, Parameters):\n",
    "        # Checking that data has the right input dimension    def Forward(self, Data, Parameters):\n",
    "        InputDimension = self.Architecture[0]\n",
    "        if Data.size(1) != InputDimension:\n",
    "            print('Dimensions of the data and the network input mismatch: data: %d, model: %d'\n",
    "                  %(Data.size(1), InputDimension))\n",
    "            raise ValueError\n",
    "\n",
    "        # Checking that preprocess has been initialised\n",
    "        if not hasattr(self, 'Shift'):\n",
    "            raise ValueError\n",
    "            \n",
    "        with torch.no_grad(): \n",
    "            Data = self.Preprocess(Data)  \n",
    "        \n",
    "        rho = torch.ones([Data.size(0)])\n",
    "        Depth = len(self.Architecture)-1\n",
    "        \n",
    "        if Data.is_cuda:\n",
    "            rho = OurCudaTensor(rho)\n",
    "\n",
    "        x = Data\n",
    "        for Layer in self.LinearLayers[:-1]:\n",
    "            x = self.ActivationFunction(Layer(x))\n",
    "        # output layer ranges from -inf to +inf\n",
    "        x = self.LinearLayers[-1](x)\n",
    "\n",
    "        #for Layer in self.LinearLayers:\n",
    "        #    x = self.ActivationFunction(Layer(x))\n",
    "        # output layer ranges from -inf to +inf\n",
    "        # x = self.LinearLayers[-1](x)\n",
    "        \n",
    "        #for (x_row, n_row) in zip(x, NuisanceParameters):\n",
    "        #    rho += x_row.mul(n_row).sum()\n",
    "        #print(NuisanceParameters.device)\n",
    "        \n",
    "        rho = (1. + x)**2\n",
    "    \n",
    "        # This does not work because it takes the tensors onto cpu\n",
    "        #rho += torch.Tensor([x_row.mul(n_row).sum() for (x_row, n_row) in zip(x, NuisanceParameters)])\n",
    "        \n",
    "        # This does not work because it takes too much space\n",
    "        #rho += torch.diagonal(torch.mm(x, NuisanceParameters.transpose(1, 0)))\n",
    "                \n",
    "        return (rho.div(1.+rho)).view(-1, 1)\n",
    "    \n",
    "    \n",
    "### Clip the weights      \n",
    "    def ClipL1Norm(self):\n",
    "        def ClipL1NormLayer(DesignatedL1Max, Layer, Counter):\n",
    "            if Counter == 1:\n",
    "                ### this avoids clipping the first layer\n",
    "                return\n",
    "            L1 = Layer.weight.abs().sum()\n",
    "            Layer.weight.masked_scatter_(L1 > DesignatedL1Max, \n",
    "                                        Layer.weight*(DesignatedL1Max/L1))\n",
    "            return\n",
    "        \n",
    "        Counter = 0\n",
    "        for m in self.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                Counter += 1\n",
    "                with torch.no_grad():\n",
    "                    DesignatedL1Max = m.weight.size(0)*m.weight.size(1)*self.L1perUnit\n",
    "                    ClipL1NormLayer(DesignatedL1Max, m, Counter)\n",
    "            else:\n",
    "                for mm in m:\n",
    "                    Counter +=1\n",
    "                    with torch.no_grad():\n",
    "                        DesignatedL1Max = mm.weight.size(0)*m.weight.size(1)*self.L1perUnit\n",
    "                        ClipL1NormLayer(DesignatedL1Max, mm, Counter)\n",
    "        return             \n",
    "            \n",
    "### This can be run only ONCE to initialize the preprocess (shift and scaling) parameters\n",
    "### Takes as input the training Data and the training Parameters as Torch tensors.\n",
    "    def InitPreprocess(self, Data):\n",
    "        # Here we do not check redundancy\n",
    "        ### NOTICE: nuisance parameters do not enter the game until the loss function        \n",
    "        \n",
    "        if not hasattr(self, 'Scaling'):\n",
    "            print('Initializing Preprocesses Variables')\n",
    "            self.Scaling = Data.std(0)\n",
    "            self.Shift = Data.mean(0)          \n",
    "        else: print('Preprocess can be initialized only once. Parameters unchanged.')\n",
    "            \n",
    "            \n",
    "### Returns scaled/shifted data and parameters\n",
    "### Takes as input Data and Parameters as Torch tensors.\n",
    "    def Preprocess(self, Data):\n",
    "        ### NOTICE: nuisance parameters do not enter the game until the loss function\n",
    "        \n",
    "        if  not hasattr(self, 'Scaling'): print('Preprocess parameters are not initialized.')\n",
    "        Data = (Data - self.Shift)/self.Scaling\n",
    "        return Data    \n",
    "\n",
    "    \n",
    "### Saves the model in Folder/Name\n",
    "    def Save(self, Name, Folder, csvFormat=False):\n",
    "        FileName = Folder + Name + '.pth'\n",
    "        torch.save({'StateDict': self.state_dict(), \n",
    "                   'Scaling': self.Scaling,\n",
    "                   'Shift': self.Shift}, \n",
    "                   FileName)\n",
    "        print('Model successfully saved.')\n",
    "        print('Path: %s'%str(FileName))\n",
    "        \n",
    "        if csvFormat:\n",
    "            modelparams = [w.detach().tolist() for w in self.parameters()]\n",
    "            np.savetxt(Folder + Name + ' (StateDict).csv', modelparams, '%s')\n",
    "            statistics = [self.Shift.detach().tolist(), self.Scaling.detach().tolist()]\n",
    "            np.savetxt(Folder + Name + ' (Statistics).csv', statistics, '%s')\n",
    "    \n",
    "### Loads the model from Folder/Name\n",
    "    def Load(self, Name, Folder):\n",
    "        FileName = Folder + Name + '.pth'\n",
    "        try:\n",
    "            IncompatibleKeys = self.load_state_dict(torch.load(FileName)['StateDict'])\n",
    "        except KeyError:\n",
    "            print('No state dictionary saved. Loading model failed.')\n",
    "            return \n",
    "        \n",
    "        if list(IncompatibleKeys)[0]:\n",
    "            print('Missing Keys: %s'%str(list(IncompatibleKeys)[0]))\n",
    "            print('Loading model failed. ')\n",
    "            return \n",
    "        \n",
    "        if list(IncompatibleKeys)[1]:\n",
    "            print('Unexpected Keys: %s'%str(list(IncompatibleKeys)[0]))\n",
    "            print('Loading model failed. ')\n",
    "            return \n",
    "        \n",
    "        self.Scaling = torch.load(FileName)['Scaling']\n",
    "        self.Shift = torch.load(FileName)['Shift']\n",
    "        \n",
    "        print('Model successfully loaded.')\n",
    "        print('Path: %s'%str(FileName))\n",
    "        \n",
    "    def Report(self): ### is it possibe to check if the model is in double?\n",
    "        print('\\nModel Report:')\n",
    "        print('Preprocess Initialized: ' + str(hasattr(self, 'Shift')))\n",
    "        print('Architecture: ' + str(self.Architecture))\n",
    "        print('Loss Function: ' + 'Linear')\n",
    "        print('Activation: ' + str(self.ActivationFunction))\n",
    "        \n",
    "    def cuda(self):\n",
    "        nn.Module.cuda(self)\n",
    "        self.Shift = self.Shift.cuda()\n",
    "        self.Scaling = self.Scaling.cuda()\n",
    "        \n",
    "    def cpu(self):\n",
    "        self.Shift = self.Shift.cpu()\n",
    "        self.Scaling = self.Scaling.cpu()\n",
    "        return nn.Module.cpu(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Files for Process: W+Z, with new physics Parameters: ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "No BSM files input. Skipping loading BSM files.\n",
      "No BSM files input. Skipping loading BSM data.\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Nuisance_Data/ChP_pt300_sm_nuisance1.h5\n",
      "##### File Info:\n",
      "{SM} = {0., 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Nuisance_Events/ChP_pt300_sm_nuisance1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "No BSM files input. Simply assign SM data.\n",
      "\n",
      "Loaded SM Files:\n",
      "['Gphi[TeV**-2]', 'GW[TeV**-2]']           #Data    XS[pb](avg.w)\n",
      "---------------------------------------  -------  ---------------\n",
      "tensor([[0., 0.]], dtype=torch.float64)  3000000         0.734385\n",
      "####\n",
      "Anlges at position [3, 5] have been converted to Sin and Cos and put at the last columns of the Data.\n",
      "####\n"
     ]
    }
   ],
   "source": [
    "DataFolder = '/data3/WZ_new_project/h5/Ideal_Nuisance_Data/'\n",
    "\n",
    "td = OurTrainingData([DataFolder + 'ChP_pt300_sm_nuisance1.h5',],\n",
    "                     [],\n",
    "                     process = 'W+Z', parameters =['Gphi[TeV**-2]', 'GW[TeV**-2]'], \n",
    "                     SMNLimits=int(3e6),\n",
    "                     BSMNLimits=int(5e5))\n",
    "\n",
    "NumEpochs = int(1e4)\n",
    "\n",
    "td.Data = td.Data[:, :7]\n",
    "td.CurateAngles([3, 5])\n",
    "\n",
    "Data, ParVal, Labels, Weights, PDFWeights = td.Data, td.ParVal, td.Labels, td.Weights, td.PDFWeights\n",
    "Data, ParVal, Labels, Weights, PDFWeights = Data.float(), ParVal.float(), Labels.float(), Weights.float(), PDFWeights.float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0199, 0.9903, 1.0012,  ..., 1.0000, 0.9975, 0.9997],\n",
       "        [1.0051, 0.9847, 1.0000,  ..., 1.0003, 0.9987, 1.0003],\n",
       "        [1.0058, 0.9848, 1.0000,  ..., 1.0003, 0.9987, 1.0002],\n",
       "        ...,\n",
       "        [1.0069, 0.9849, 1.0001,  ..., 1.0003, 0.9986, 1.0002],\n",
       "        [1.0062, 0.9848, 1.0001,  ..., 1.0003, 0.9987, 1.0002],\n",
       "        [1.0086, 0.9853, 1.0001,  ..., 1.0004, 0.9985, 1.0001]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDFWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8000e+08)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(PDFWeights + 1.).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Files for Process: W+Z, with new physics Parameters: ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "No BSM files input. Skipping loading BSM files.\n",
      "No BSM files input. Skipping loading BSM data.\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Nuisance_Data/ChP_pt300_sm_nuisance1.h5\n",
      "##### File Info:\n",
      "{SM} = {0., 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Nuisance_Events/ChP_pt300_sm_nuisance1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "No BSM files input. Simply assign SM data.\n",
      "\n",
      "Loaded SM Files:\n",
      "['Gphi[TeV**-2]', 'GW[TeV**-2]']           #Data    XS[pb](avg.w)\n",
      "---------------------------------------  -------  ---------------\n",
      "tensor([[0., 0.]], dtype=torch.float64)  3000000         0.734385\n",
      "####\n",
      "Anlges at position [3, 5] have been converted to Sin and Cos and put at the last columns of the Data.\n",
      "####\n",
      "Initializing Preprocesses Variables\n",
      "Training epoch 10 (took 3.37 sec, time left 0:50:56.995074 sec) loss 0.24997696\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (10000 epochs Seed590), 10 epoch.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chen/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 100 (took 29.96 sec, time left 0:54:26.122845 sec) loss 0.23957904\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (10000 epochs Seed590), 100 epoch.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7b8542edc0c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mrandom_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1339\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m OT.Train(MD, Data = Data, PDFWeights = PDFWeights, Labels=Labels, Weights= Weights, bs = 100000,\n\u001b[0m\u001b[1;32m     27\u001b[0m         Name = 'PDF_ChPsm, (%d epochs Seed%d), '%(NumEpochs, random_seed), Folder = os.getcwd()+'/TrainedModels/')\n",
      "\u001b[0;32m<ipython-input-2-6369d5b571f8>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, model, Data, PDFWeights, Labels, Weights, bs, L1perUnit, UseGPU, Name, Folder, WeightClipping, L1Max)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mOptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0moutput\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mtempmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempPDFWeights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 loss            = self.Criterion(output, tempLabels[b:b+mini_batch_size].reshape(-1,1), \n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DataFolder = '/data3/WZ_new_project/h5/Ideal_Nuisance_Data/'\n",
    "\n",
    "td = OurTrainingData([DataFolder + 'ChP_pt300_sm_nuisance1.h5',],\n",
    "                     [],\n",
    "                     process = 'W+Z', parameters =['Gphi[TeV**-2]', 'GW[TeV**-2]'], \n",
    "                     SMNLimits=int(3e6),\n",
    "                     BSMNLimits=int(5e5))\n",
    "\n",
    "NumEpochs = int(1e4)\n",
    "\n",
    "td.Data = td.Data[:, :7]\n",
    "td.CurateAngles([3, 5])\n",
    "\n",
    "Data, ParVal, Labels, Weights, PDFWeights = td.Data, td.ParVal, td.Labels, td.Weights, td.PDFWeights\n",
    "Data, ParVal, Labels, Weights, PDFWeights = Data.float(), ParVal.float(), Labels.float(), Weights.float(), PDFWeights.float()\n",
    "\n",
    "\n",
    "MD = OurLinearModel(NumberOfNuisanceParameters=PDFWeights.size(1), AR=[9,32,32,32,30])\n",
    "\n",
    "MD.InitPreprocess(Data, PDFWeights)\n",
    "\n",
    "OT = OurTrainer(NumEpochs = NumEpochs)\n",
    "OT.SetSaveAfterEpochs([10,100,500]+list(range(1000, 11000, 1000)))\n",
    "\n",
    "random_seed = torch.randint(0, 1339, (1,)).item()\n",
    "OT.Train(MD, Data = Data, PDFWeights = PDFWeights, Labels=Labels, Weights= Weights, bs = 100000,\n",
    "        Name = 'PDF_ChPsm, (%d epochs Seed%d), '%(NumEpochs, random_seed), Folder = os.getcwd()+'/TrainedModels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weights[0]*3e6\n",
    "x * PDFWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0199, 0.9903, 1.0012,  ..., 1.0000, 0.9975, 0.9997],\n",
       "        [1.0051, 0.9847, 1.0000,  ..., 1.0003, 0.9987, 1.0003],\n",
       "        [1.0058, 0.9848, 1.0000,  ..., 1.0003, 0.9987, 1.0002],\n",
       "        ...,\n",
       "        [1.0069, 0.9849, 1.0001,  ..., 1.0003, 0.9986, 1.0002],\n",
       "        [1.0062, 0.9848, 1.0001,  ..., 1.0003, 0.9987, 1.0002],\n",
       "        [1.0086, 0.9853, 1.0001,  ..., 1.0004, 0.9985, 1.0001]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(PDFWeights+1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Files for Process: W+Z, with new physics Parameters: ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "No BSM files input. Skipping loading BSM files.\n",
      "No BSM files input. Skipping loading BSM data.\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Nuisance_Data/ChP_pt300_sm_nuisance.h5\n",
      "##### File Info:\n",
      "SM = {0., 0.}[TeV**-2] data, Ideal_Nuisance Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Nuisance_Events/ChP_pt300_sm_nuisance.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "No BSM files input. Simply assign SM data.\n",
      "\n",
      "Loaded SM Files:\n",
      "['Gphi[TeV**-2]', 'GW[TeV**-2]']           #Data    XS[pb](avg.w)\n",
      "---------------------------------------  -------  ---------------\n",
      "tensor([[0., 0.]], dtype=torch.float64)     1000         0.734385\n",
      "####\n",
      "Anlges at position [3, 5] have been converted to Sin and Cos and put at the last columns of the Data.\n",
      "####\n",
      "Initializing Preprocesses Variables\n",
      "Training epoch 2 (took 0.01 sec, time left 0:00:01.546584 sec) loss 296.44689941\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (500 epochs Seed219), 2 epoch.pth\n",
      "Training epoch 5 (took 0.02 sec, time left 0:00:02.450446 sec) loss 125.64768219\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (500 epochs Seed219), 5 epoch.pth\n",
      "Training epoch 10 (took 0.03 sec, time left 0:00:02.584600 sec) loss 14.07734013\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (500 epochs Seed219), 10 epoch.pth\n",
      "Training epoch 50 (took 0.18 sec, time left 0:00:02.058614 sec) loss 0.16819677\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (500 epochs Seed219), 50 epoch.pth\n",
      "Training epoch 100 (took 0.22 sec, time left 0:00:01.779965 sec) loss 0.07973805\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (500 epochs Seed219), 100 epoch.pth\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (500 epochs Seed219), Final.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OurLinearModel(\n",
       "  (LinearLayers): ModuleList(\n",
       "    (0): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Linear(in_features=32, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFolder = '/data3/WZ_new_project/h5/Ideal_Nuisance_Data/'\n",
    "\n",
    "td = OurTrainingData([DataFolder + 'ChP_pt300_sm_nuisance.h5',],\n",
    "                     [],\n",
    "                     process = 'W+Z', parameters =['Gphi[TeV**-2]', 'GW[TeV**-2]'], \n",
    "                     SMNLimits=int(3e6),\n",
    "                     BSMNLimits=int(5e5))\n",
    "\n",
    "NumEpochs = int(5e2)\n",
    "\n",
    "td.Data = td.Data[:, :7]\n",
    "td.CurateAngles([3, 5])\n",
    "\n",
    "Data, ParVal, Labels, Weights, PDFWeights = td.Data, td.ParVal, td.Labels, td.Weights, td.PDFWeights\n",
    "Data, ParVal, Labels, Weights, PDFWeights = Data.float(), ParVal.float(), Labels.float(), Weights.float(), PDFWeights.float()\n",
    "\n",
    "\n",
    "MD = OurLinearModel(NumberOfNuisanceParameters=PDFWeights.size(1), AR=[9,32,32,32,30])\n",
    "\n",
    "MD.InitPreprocess(Data, PDFWeights)\n",
    "\n",
    "OT = OurTrainer(NumEpochs = NumEpochs)\n",
    "OT.SetSaveAfterEpochs([2, 5, 10, 50, 100])\n",
    "\n",
    "random_seed = torch.randint(0, 1339, (1,)).item()\n",
    "OT.Train(MD, Data = Data, PDFWeights = PDFWeights, Labels=Labels, Weights= Weights, bs = 100000,\n",
    "        Name = 'PDF_ChPsm, (%d epochs Seed%d), '%(NumEpochs, random_seed), Folder = os.getcwd()+'/TrainedModels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Files for Process: W+Z, with new physics Parameters: ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "No BSM files input. Skipping loading BSM files.\n",
      "No BSM files input. Skipping loading BSM data.\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Nuisance_Data/ChP_pt300_sm_nuisance1.h5\n",
      "##### File Info:\n",
      "{SM} = {0., 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Nuisance_Events/ChP_pt300_sm_nuisance1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "No BSM files input. Simply assign SM data.\n",
      "\n",
      "Loaded SM Files:\n",
      "['Gphi[TeV**-2]', 'GW[TeV**-2]']           #Data    XS[pb](avg.w)\n",
      "---------------------------------------  -------  ---------------\n",
      "tensor([[0., 0.]], dtype=torch.float64)  3000000         0.734385\n",
      "####\n",
      "Anlges at position [3, 5] have been converted to Sin and Cos and put at the last columns of the Data.\n",
      "####\n",
      "Initializing Preprocesses Variables\n",
      "Training epoch 10 (took 5.84 sec, time left 1:28:25.603383 sec) loss 0.30881980\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 10 epoch.pth\n",
      "Training epoch 100 (took 36.01 sec, time left 1:08:22.056679 sec) loss 0.03834499\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 100 epoch.pth\n",
      "Training epoch 500 (took 145.61 sec, time left 0:59:14.424963 sec) loss 0.00416799\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 500 epoch.pth\n",
      "Training epoch 1000 (took 183.08 sec, time left 0:55:31.203394 sec) loss 0.01244533\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 1000 epoch.pth\n",
      "Training epoch 2000 (took 369.39 sec, time left 0:49:17.884365 sec) loss nan\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 2000 epoch.pth\n",
      "Training epoch 3000 (took 357.29 sec, time left 0:42:38.973242 sec) loss nan\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 3000 epoch.pth\n",
      "Training epoch 4000 (took 361.34 sec, time left 0:36:26.941760 sec) loss nan\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 4000 epoch.pth\n",
      "Training epoch 5000 (took 362.32 sec, time left 0:30:20.158273 sec) loss nan\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 5000 epoch.pth\n",
      "Training epoch 6000 (took 366.77 sec, time left 0:24:17.827706 sec) loss nan\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 6000 epoch.pth\n",
      "Training epoch 7000 (took 361.59 sec, time left 0:18:12.014020 sec) loss nan\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 7000 epoch.pth\n",
      "Training epoch 8000 (took 359.83 sec, time left 0:12:06.813807 sec) loss nan\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 8000 epoch.pth\n",
      "Training epoch 9000 (took 362.22 sec, time left 0:06:03.073659 sec) loss nan\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 9000 epoch.pth\n",
      "Training epoch 10000 (took 362.14 sec, time left -1 day, 23:59:59.636693 sec) loss nan\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), 10000 epoch.pth\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPsm, (Seed803), Final.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OurLinearModel(\n",
       "  (LinearLayers): ModuleList(\n",
       "    (0): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Linear(in_features=32, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFolder = '/data3/WZ_new_project/h5/Ideal_Nuisance_Data/'\n",
    "\n",
    "td = OurTrainingData([DataFolder + 'ChP_pt300_sm_nuisance1.h5',],\n",
    "                     [],\n",
    "                     process = 'W+Z', parameters =['Gphi[TeV**-2]', 'GW[TeV**-2]'], \n",
    "                     SMNLimits=int(3e6),\n",
    "                     BSMNLimits=int(5e5))\n",
    "\n",
    "NumEpochs = int(1e4)\n",
    "\n",
    "td.Data = td.Data[:, :7]\n",
    "td.CurateAngles([3, 5])\n",
    "\n",
    "Data, ParVal, Labels, Weights, PDFWeights = td.Data, td.ParVal, td.Labels, td.Weights, td.PDFWeights\n",
    "Data, ParVal, Labels, Weights, PDFWeights = Data.float(), ParVal.float(), Labels.float(), Weights.float(), PDFWeights.float()\n",
    "\n",
    "\n",
    "MD = OurLinearModel(NumberOfNuisanceParameters=PDFWeights.size(1), AR=[9,32,32,32,30])\n",
    "\n",
    "MD.InitPreprocess(Data, PDFWeights)\n",
    "\n",
    "OT = OurTrainer(NumEpochs = NumEpochs)\n",
    "#OT.SetSaveAfterEpochs([2, 5, 10, 50, 100])\n",
    "OT.SetSaveAfterEpochs([10,100,500]+list(range(1000, 11000, 1000)))\n",
    "\n",
    "random_seed = torch.randint(0, 1339, (1,)).item()\n",
    "OT.Train(MD, Data = Data, PDFWeights = PDFWeights, Labels=Labels, Weights= Weights, bs = 100000,\n",
    "        Name = 'PDF_ChPsm, (Seed%d), '%(random_seed), Folder = os.getcwd()+'/TrainedModels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.6950e-01, -7.7182e-01, -5.0821e+00, -2.8026e-01, -5.0841e+00,\n",
       "        -2.6051e+00,  1.2432e+00, -5.4303e+00,  4.8934e-01,  1.1250e+01,\n",
       "         3.3053e+00,  5.3394e+00, -3.8319e+00,  6.5590e+00, -1.4015e+00,\n",
       "         6.5070e+00,  3.6241e+00, -4.1672e+00,  3.8679e+00,  3.3754e+00,\n",
       "        -2.0062e+00,  2.6262e-01,  8.3906e+00,  6.2406e+00, -2.2632e+00,\n",
       "        -2.6826e+00, -4.1474e+00,  3.5640e-01,  8.2733e-01,  1.6812e+01,\n",
       "         3.6203e+00, -5.2453e+00, -1.4936e+00, -1.2950e+00, -1.5819e-02,\n",
       "        -3.0986e+00, -3.3146e+00,  4.9225e+00, -2.1250e+00, -7.4657e+00,\n",
       "        -9.1318e+00, -7.1829e+00,  3.4107e+00, -8.7743e+00,  3.2676e+00,\n",
       "        -6.2030e-01,  1.4194e+00, -5.1237e+00, -6.2177e+00,  1.7407e+00,\n",
       "         2.0525e+00,  7.2686e+00, -1.3974e+01, -2.0216e+00,  1.0131e+00,\n",
       "        -1.3825e+00,  6.1772e+00,  3.5166e+00, -2.8303e+00, -4.8519e-01,\n",
       "         6.3701e+00,  1.7746e+00, -1.2558e+01, -1.0502e+01,  6.1170e-02,\n",
       "         4.5053e+00, -1.0221e+01, -1.1302e+00, -3.7390e+00, -6.3673e+00,\n",
       "         7.2168e+00,  2.8425e+00, -1.0109e+00,  7.4480e+00,  1.4389e+00,\n",
       "         5.1593e-01, -7.7750e-01,  1.6211e+00, -2.7382e+00, -1.6461e+00,\n",
       "         7.9286e+00,  7.0698e-01,  2.5351e+00, -4.0830e+00, -1.4250e+00,\n",
       "         3.5725e+00,  1.6086e+00,  4.0479e+00,  3.1150e+00, -4.7161e+00,\n",
       "         1.1246e+01,  3.9969e+00, -4.0432e+00,  8.1613e-01,  1.4270e-01,\n",
       "         5.2218e+00,  5.9410e+00,  5.2533e+00, -4.1661e+00,  3.4476e+00,\n",
       "        -1.7437e+00, -2.0975e+00,  8.7152e+00,  9.6208e-01,  8.2055e+00,\n",
       "         7.1970e+00, -4.6825e+00, -8.0429e+00, -2.8780e+00, -1.6519e+00,\n",
       "         6.6866e+00, -7.9628e-01,  5.8721e+00,  4.3304e+00, -5.8420e-01,\n",
       "         1.0866e+01,  6.5542e+00, -5.1230e+00,  9.4359e+00, -2.4039e+00,\n",
       "        -8.2752e-01,  5.7309e+00, -4.9716e+00,  3.3162e+00,  1.0801e+01,\n",
       "        -2.2532e+00, -2.5433e+00,  6.0902e+00,  5.9343e+00,  9.3982e-01,\n",
       "         2.0129e+00, -1.3418e+00, -6.0201e+00, -9.1316e+00, -1.2488e+01,\n",
       "        -2.0301e+00,  1.1896e+01, -3.7918e+00, -2.7060e+00, -6.5272e+00,\n",
       "         2.5961e+00,  3.3996e+00, -6.4590e+00,  1.5024e+00,  2.8372e+00,\n",
       "         3.5723e+00, -5.6741e+00, -3.6337e+00, -4.8129e+00,  5.1529e+00,\n",
       "        -9.1993e-01,  7.9236e-01,  2.9264e+00, -6.7885e-01,  3.5158e+00,\n",
       "         9.3029e+00,  8.0516e+00,  4.1207e-01, -8.5052e-01, -1.8434e+00,\n",
       "         8.4990e+00, -5.1561e+00,  4.7172e+00,  3.1132e+00,  1.0907e+01,\n",
       "         4.8533e-02, -7.3667e+00,  3.7012e+00, -4.5466e+00,  4.5626e+00,\n",
       "         1.3823e+01, -9.9056e+00, -3.9667e+00,  8.7148e+00,  1.0819e+01,\n",
       "         2.7361e+00,  4.0364e+00, -7.7842e+00, -6.6876e+00, -8.4126e-01,\n",
       "         7.2239e+00, -4.9463e+00,  1.1855e-02,  4.6008e-01,  2.6426e+00,\n",
       "         6.2498e+00, -4.1134e+00, -1.0019e+00,  6.4561e+00,  7.1777e+00,\n",
       "        -3.1356e+00, -6.4516e+00, -7.7132e-01,  6.4298e+00, -4.9552e-01,\n",
       "         5.4340e+00, -8.1068e+00, -3.1152e-01, -3.5038e+00,  1.9321e+00,\n",
       "         4.8039e+00,  5.2696e+00, -5.4348e+00,  5.5455e+00, -6.9008e+00,\n",
       "        -1.2193e+01, -8.9805e+00, -1.9982e+00,  5.0469e+00, -2.1309e+00,\n",
       "         3.9612e+00, -4.8849e+00,  4.9126e+00,  1.1066e+00, -2.7268e+00,\n",
       "        -1.1317e+01, -1.7320e+00,  2.4157e+00,  1.0885e-01,  1.8430e-01,\n",
       "         7.1131e+00, -1.4604e+01, -3.2607e+00, -4.2387e+00,  6.6024e+00,\n",
       "         2.9844e+00,  4.1234e+00,  3.8744e+00, -5.2363e-01,  7.8403e+00,\n",
       "         5.0775e+00,  6.5801e+00, -6.6916e-01,  1.8057e+00,  5.5120e+00,\n",
       "        -7.9870e+00, -1.1100e+00, -7.0462e+00, -3.0606e+00,  8.7428e+00,\n",
       "         6.0349e-01, -5.1446e+00, -4.2274e+00, -7.8649e+00,  6.6509e+00,\n",
       "         3.1757e+00,  4.4056e+00, -9.1854e+00, -6.9970e+00, -5.3241e+00,\n",
       "         2.1703e+00, -5.3573e+00,  7.5880e+00,  5.0197e+00, -2.7210e+00,\n",
       "         3.4126e-01,  1.0701e+00, -4.3567e+00,  4.2632e+00, -2.1615e+00,\n",
       "         9.8273e+00, -1.0844e+01, -6.0182e+00,  6.0102e+00, -1.3115e+00,\n",
       "         1.5425e+00,  5.9666e+00,  1.4292e+00,  8.2631e+00, -1.6712e+00,\n",
       "         2.0839e+00, -6.6269e+00,  1.7432e+00,  1.3717e+01,  4.2257e+00,\n",
       "        -8.4541e+00, -6.7450e+00,  6.0119e+00, -8.2107e+00,  7.4848e+00,\n",
       "        -4.6934e+00, -1.2503e+01, -8.9241e-01, -4.7206e+00, -1.8950e+00,\n",
       "        -5.1515e-01, -8.2460e-01,  1.1413e-01,  3.4319e+00,  6.4031e-01,\n",
       "         6.8232e+00,  4.4166e+00, -6.6810e-01,  9.7651e+00, -2.7182e+00,\n",
       "        -8.1115e+00,  2.3525e+00,  5.6127e-02, -8.2904e+00, -2.5611e+00,\n",
       "        -5.3251e+00,  1.7396e+00,  2.8814e+00,  1.5163e+00, -1.2959e+00,\n",
       "        -9.5953e+00,  6.6996e+00, -1.0334e+01, -1.0513e+00, -8.0418e+00,\n",
       "         3.0701e-01,  4.1246e+00,  6.1808e+00, -1.2449e+00,  4.3424e-01,\n",
       "         2.9423e+00,  3.1104e+00,  9.4471e+00,  2.2005e+00,  6.3156e+00,\n",
       "        -1.5609e+00,  1.0925e+00, -3.5216e+00,  9.2431e+00, -7.4865e+00,\n",
       "         1.0502e-01,  5.8417e+00, -3.6481e-01,  2.5794e+00,  2.6464e+00,\n",
       "        -4.9905e+00,  3.4390e+00, -9.8438e+00,  1.7775e+00,  3.6706e+00,\n",
       "         3.8889e+00,  4.4992e+00, -5.3629e+00, -4.4728e+00,  3.8100e+00,\n",
       "         1.0864e+01,  6.1040e+00,  1.6896e+00, -2.4498e+00, -4.1572e-01,\n",
       "        -6.1291e-01,  2.6523e+00,  9.6173e+00, -7.9607e-01, -1.8795e+00,\n",
       "         2.3980e+00, -3.9320e+00,  1.3469e+01,  1.4331e+00,  1.0089e+01,\n",
       "        -7.4193e+00, -2.2906e-01, -3.5185e+00,  2.4682e+00,  8.8502e+00,\n",
       "        -7.3460e+00, -6.0068e-02,  5.0777e+00, -5.4302e+00,  2.5757e+00,\n",
       "         4.3389e+00, -4.3784e+00, -1.3893e+01,  6.5123e+00, -3.6895e+00,\n",
       "        -2.3861e-01, -1.1431e+01, -8.4171e-02, -5.1710e+00,  7.0831e+00,\n",
       "         4.2371e+00,  1.1358e+00,  5.3524e+00,  6.2538e+00, -2.2049e+00,\n",
       "         4.2703e+00,  5.0120e+00, -4.2031e+00,  2.3639e+00,  2.7400e+00,\n",
       "         5.4157e-01,  4.4073e+00, -5.7182e+00,  3.0476e+00,  5.8783e+00,\n",
       "        -1.2685e+01, -7.0497e+00,  7.4005e+00, -1.7916e+00, -1.9435e+01,\n",
       "         1.6721e+00, -7.2852e-03,  3.1997e+00,  6.5182e+00,  6.9254e+00,\n",
       "        -7.1192e-01,  1.1919e+00,  1.7481e+00,  5.3796e-01,  1.8067e-01,\n",
       "         5.7969e+00,  9.3569e+00, -6.4736e+00, -9.2700e+00, -5.2445e+00,\n",
       "        -6.7406e-01, -4.3869e+00,  5.9149e+00,  1.5234e+00, -3.0902e+00,\n",
       "         3.1051e+00, -4.3726e+00,  7.3942e+00,  8.7492e+00,  7.0495e+00,\n",
       "         1.2020e+00,  5.4714e+00, -2.4717e+00,  6.7163e+00,  2.3771e+00,\n",
       "        -3.4939e+00,  4.8642e+00, -7.2443e+00, -5.6889e+00, -5.6748e+00,\n",
       "        -1.2601e+01, -1.3688e+00,  1.9593e+00, -4.5262e+00,  6.9920e+00,\n",
       "         8.5189e+00, -4.6411e+00,  2.4987e+00, -2.8772e-01,  2.1051e+00,\n",
       "         2.7252e+00,  8.3313e-02, -3.4235e+00, -1.2830e+00, -2.5111e+00,\n",
       "        -7.7472e-01, -3.3881e+00, -5.7401e+00,  1.3679e+00,  1.0771e+01,\n",
       "        -9.0627e-01, -9.4912e-01,  1.7936e+00,  1.1886e+00, -3.1978e-01,\n",
       "        -4.5647e+00, -4.4396e+00,  8.3385e-01,  6.8302e+00,  6.7495e+00,\n",
       "        -1.2906e+00, -5.7413e+00, -2.9907e-01, -2.1360e+00,  4.0626e+00,\n",
       "        -9.2197e-01, -8.6470e+00,  7.2092e-01,  1.5997e+00, -1.5371e+01,\n",
       "         4.4167e+00, -2.8581e+00,  3.1059e+00, -1.4834e+01,  7.7230e+00,\n",
       "         2.3644e+00, -1.0467e+01,  7.1976e+00, -1.0185e+01,  6.6357e+00,\n",
       "         4.8170e+00, -1.1856e+01, -4.6595e+00,  6.4601e+00, -8.5256e+00,\n",
       "         9.7988e-01, -8.4840e+00,  3.4645e+00,  2.9356e+00, -2.4167e+00,\n",
       "        -5.7147e+00, -3.9659e+00, -1.5735e+00, -2.7092e+00, -6.5093e-01,\n",
       "        -3.9543e+00,  3.3511e+00,  7.0443e+00,  5.1538e-01,  3.9174e+00,\n",
       "         3.9215e+00, -8.2754e+00,  1.0302e+00,  6.1126e+00,  7.3755e+00,\n",
       "         3.8570e+00, -1.2609e+01,  6.1351e+00, -2.3326e+00,  3.2136e+00,\n",
       "        -2.5064e+00, -3.0516e+00, -4.0082e+00, -3.9848e+00, -3.9670e+00,\n",
       "         5.9588e+00,  1.5077e+00, -2.9868e-01, -2.3035e+00, -1.9753e+00,\n",
       "        -2.5781e+00, -1.9940e+00, -6.3823e+00, -1.4989e+00,  3.5079e+00,\n",
       "         9.0300e-01, -9.8688e+00,  1.1674e+00, -1.0533e-02,  6.8487e+00,\n",
       "         4.0933e-01,  3.4183e+00, -9.0994e+00,  3.3434e+00, -4.5076e+00,\n",
       "         1.7679e+00,  8.1798e+00,  8.0898e+00, -6.8372e+00, -8.9064e-01,\n",
       "        -2.8932e+00, -3.0201e+00, -3.2100e-01, -9.9383e+00,  1.1183e+01,\n",
       "         5.5190e+00,  8.7124e-01, -2.1366e+00, -5.0706e-01,  5.6975e+00,\n",
       "        -1.2945e+00, -7.6067e+00, -2.7330e+00,  8.8694e+00,  5.1368e+00,\n",
       "         1.7144e+00,  3.0924e-02,  7.6242e-02, -3.3278e+00, -2.9211e+00,\n",
       "         5.1635e-01, -3.2615e+00,  3.7545e+00, -2.4807e+00,  9.1663e+00,\n",
       "        -6.6788e+00,  3.7152e+00, -1.0059e+01,  5.4136e-01,  5.9208e+00,\n",
       "         4.4757e+00, -3.4555e+00,  7.0500e+00, -4.3375e+00, -7.5514e+00,\n",
       "         1.4368e+00, -1.2482e+00,  4.4061e+00, -4.4190e+00, -7.7198e+00,\n",
       "        -5.7354e-01,  2.7663e+00,  3.3868e+00, -5.0570e+00, -6.0204e+00,\n",
       "        -4.7595e+00, -2.2036e+00, -6.5260e+00, -3.3193e+00, -3.9611e+00,\n",
       "         2.4500e+00,  5.9280e+00,  1.0019e+00,  1.1014e+00, -7.7496e+00,\n",
       "        -3.8489e+00,  7.3489e+00,  7.0569e+00, -2.9953e+00,  3.8360e+00,\n",
       "        -6.6286e+00, -1.9397e+00, -4.1223e+00,  2.8999e+00,  1.7811e+00,\n",
       "         9.2592e-01,  6.3145e+00, -4.4947e+00, -8.9956e-01, -3.8773e+00,\n",
       "        -4.6384e+00, -2.8648e+00, -1.0001e+00,  3.3943e+00,  8.6315e+00,\n",
       "        -7.3346e-01, -1.5967e+00, -4.4429e+00, -4.7910e+00, -8.6566e-01,\n",
       "         8.6528e+00,  8.3874e+00,  1.4237e+01, -3.6202e+00,  1.6233e-01,\n",
       "        -4.5757e+00, -3.3939e-01, -3.5666e+00, -8.4440e+00, -2.0640e+00,\n",
       "        -5.6894e+00, -1.1073e+01, -2.8704e+00,  2.6217e+00,  2.9377e+00,\n",
       "         7.6110e+00,  1.7203e-01,  5.5711e+00, -9.3867e+00, -2.9886e+00,\n",
       "        -4.6558e+00, -5.8284e-02,  3.2598e+00,  7.9150e+00,  2.3584e+00,\n",
       "        -1.8673e+00, -4.3389e+00,  9.7227e-01, -7.4179e+00,  1.0594e+01,\n",
       "        -6.7400e+00, -5.5863e-01,  7.1356e+00, -1.3814e+00, -8.2053e+00,\n",
       "         4.6975e-01,  4.9105e+00,  6.0155e-01,  8.3416e+00,  8.7632e+00,\n",
       "         5.8787e+00,  3.7059e+00, -8.8211e-02,  1.7936e+00, -4.1810e+00,\n",
       "        -1.1063e+00,  2.3940e-01, -3.5535e+00, -4.6974e+00,  1.0421e+01,\n",
       "         4.0120e+00,  2.2925e+00,  1.1618e+01,  7.2418e+00,  1.2090e+00,\n",
       "         3.2611e-01, -1.2199e+00,  5.7123e+00,  5.6263e+00,  7.3065e+00,\n",
       "         7.9791e+00,  1.1747e+00,  2.2770e+00,  4.7308e+00,  6.3588e+00,\n",
       "         6.6774e-01, -4.2260e-01,  1.2611e+01, -1.4570e-01, -3.4460e+00,\n",
       "         3.5423e+00, -9.8301e+00,  7.0939e+00,  3.5834e+00,  5.9978e+00,\n",
       "        -4.2808e+00, -1.2010e+00, -5.4981e+00, -2.4897e+00,  4.4099e-01,\n",
       "         1.2976e+00, -6.1982e+00,  2.3951e+00,  6.7376e+00,  4.2167e+00,\n",
       "        -5.8755e+00, -4.3164e-01, -2.7076e+00,  3.7644e+00,  3.1280e-01,\n",
       "        -4.5859e+00, -6.7596e+00, -1.0943e+01, -2.0331e+00, -3.9166e+00,\n",
       "        -1.2610e+00,  3.6023e+00, -6.4938e+00,  4.6355e-01,  9.6335e+00,\n",
       "        -9.3006e-01, -4.8105e+00, -5.8564e+00, -7.5390e+00,  3.9762e+00,\n",
       "         5.3398e+00, -5.0647e-01,  1.4980e+00,  8.7944e+00,  4.6719e+00,\n",
       "        -6.1495e+00, -6.2730e+00,  5.4525e+00, -2.7193e+00,  3.5036e+00,\n",
       "        -6.5501e-01, -2.6207e+00,  5.4975e+00,  6.9900e+00,  1.9499e+00,\n",
       "        -2.8512e-01,  2.5821e+00,  3.9757e+00,  9.4072e+00,  7.1337e+00,\n",
       "         4.9223e-01,  1.5429e+00, -2.8449e+00, -8.3368e-01, -1.7139e+00,\n",
       "         2.4330e+00,  8.7681e+00, -8.4305e+00,  7.2956e+00, -4.0663e+00,\n",
       "         2.9476e+00,  4.9119e+00, -4.3623e-01, -3.6762e+00, -5.5579e+00,\n",
       "         5.8859e+00, -1.5564e+00, -4.0617e+00, -1.2286e+00, -3.6052e+00,\n",
       "         1.3946e+00,  7.8027e-02,  8.3524e-01,  8.5274e-01,  5.3085e+00,\n",
       "         8.9056e-01, -1.2052e+00, -3.6461e+00, -5.1438e+00, -1.3644e+00,\n",
       "         1.7905e+00, -5.1038e+00,  9.1784e-01, -2.0004e+00, -7.7790e+00,\n",
       "         5.8546e+00,  9.6315e+00,  6.7642e+00, -1.8849e-02,  3.4247e+00,\n",
       "         6.7947e+00, -3.2505e+00, -6.3841e+00, -5.9180e-01,  5.3344e+00,\n",
       "         2.3285e+00,  5.1710e+00,  3.7624e+00,  4.9874e+00, -3.2983e+00,\n",
       "        -2.1404e+00,  5.4046e+00,  6.8772e+00, -5.5951e+00, -9.1952e+00,\n",
       "         8.3619e+00,  1.3522e+00, -3.8113e+00, -3.5363e+00, -1.4279e+00,\n",
       "        -1.2452e+01,  9.3436e+00,  3.0115e+00,  2.2758e+00,  3.2391e+00,\n",
       "        -5.4724e-01,  3.8953e+00,  4.8647e+00, -8.6642e+00, -2.8699e+00,\n",
       "        -3.1010e+00,  8.0098e+00, -1.1378e+01,  4.8850e-01,  9.7595e-01,\n",
       "         2.9264e+00,  1.8136e+00, -3.9826e+00, -4.6515e+00, -1.4341e+00,\n",
       "        -1.0305e+01, -1.7492e+00, -3.1213e+00, -2.1344e+00,  3.4825e+00,\n",
       "         1.8791e+01,  1.7660e+00, -3.0919e+00,  3.3413e+00,  6.7847e+00,\n",
       "        -3.2646e+00,  4.0289e+00, -3.9344e+00,  4.9283e-01, -1.1092e+00,\n",
       "         9.8308e-01,  5.1076e+00,  2.5672e+00,  1.9012e-01,  2.5643e+00,\n",
       "        -8.4776e-01, -2.5034e+00,  7.2383e+00, -3.3066e+00, -9.5952e+00,\n",
       "         2.9007e+00, -8.2134e-01, -9.1761e-02, -3.0826e+00,  4.0622e+00,\n",
       "        -7.6781e+00,  5.0185e+00,  1.0617e+00, -1.0887e+00, -1.0336e+01,\n",
       "         2.6057e+00, -1.0777e+01,  5.6242e+00,  1.3462e+00, -3.6379e+00,\n",
       "         7.3317e+00, -2.8436e+00,  4.0412e+00,  3.1302e+00, -5.5293e-01,\n",
       "        -3.4471e+00,  1.2213e+01,  6.6004e-01,  3.5587e+00, -5.6881e+00,\n",
       "        -6.8744e+00, -1.9451e+00, -5.3961e+00,  7.6516e+00, -9.6968e-01,\n",
       "        -3.5077e+00,  1.6350e+00,  3.7610e+00,  3.7515e-01, -2.1097e+00,\n",
       "         1.0248e+01, -1.5960e+00, -3.1082e-01, -6.2560e+00, -1.5216e+00,\n",
       "         4.1055e+00,  1.0080e+01,  2.0824e+01,  4.7337e+00, -2.6554e+00,\n",
       "        -4.3223e+00,  1.4595e+00,  3.1348e+00,  5.4966e+00, -7.6304e+00,\n",
       "        -5.8114e+00, -1.9384e-01, -6.5427e+00, -5.0802e-01,  6.9516e+00,\n",
       "        -4.9982e-01,  2.0589e+01,  6.1910e-01, -4.6424e-02, -5.9998e+00,\n",
       "         1.0635e+00, -2.2404e+00,  5.8176e+00,  3.3435e+00, -1.6387e+01,\n",
       "         6.1678e+00, -1.4521e+00,  2.5437e+00, -2.5866e+00,  3.1603e+00,\n",
       "         6.0905e+00,  4.2472e-01, -5.8446e+00, -1.6399e+00,  1.8258e+01,\n",
       "         5.7839e+00,  3.0643e+00, -6.5794e+00,  6.6773e+00,  3.4158e+00,\n",
       "         4.9096e-01, -2.1889e+00, -2.1614e+00,  1.4945e+00, -2.4295e+00,\n",
       "        -2.9285e+00, -9.0748e+00, -8.8708e-01,  8.9680e+00, -4.5886e+00,\n",
       "        -6.9595e+00, -7.5459e+00,  4.5118e+00,  1.2485e+00,  9.3656e+00,\n",
       "        -7.8789e-01,  3.3429e+00, -9.1074e-01,  4.2143e+00,  1.5563e+00,\n",
       "         2.7309e+00, -3.3211e+00,  6.8282e+00,  3.5261e+00,  2.8482e+00,\n",
       "         9.2569e-01,  7.2340e+00,  3.0623e+00, -2.2427e+00,  4.6769e+00,\n",
       "         9.6547e+00,  9.1363e+00,  5.2265e+00,  6.8197e+00, -3.4377e+00,\n",
       "         4.8576e+00,  1.8825e+01,  3.1669e+00,  1.1577e+00,  3.0721e+00,\n",
       "         5.9804e+00,  2.9030e+00,  1.9622e+00,  1.0014e-01,  1.2276e+00,\n",
       "        -5.3963e+00,  7.1442e-01,  1.1081e+01,  7.3023e-02,  1.0982e+01,\n",
       "         1.5572e+00, -4.3623e+00, -8.0217e+00,  4.4308e+00, -1.5392e+00,\n",
       "         5.0857e+00, -1.0616e+01,  4.1539e+00, -1.3492e+00, -7.1904e-01,\n",
       "        -2.0464e+00,  1.5406e-01, -6.3154e+00, -6.9230e-01, -7.5397e+00,\n",
       "         2.2258e+00, -1.7102e+00,  3.2661e-01, -3.3157e+00, -1.0361e+00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diagonal(torch.mm(tempx, tempn.transpose(1, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0926,  0.3688, -0.6142,  0.0646, -0.0294,  1.2173, -1.2448,  0.9657,\n",
      "         -0.8563,  0.0264,  1.1739, -0.3741,  0.2871,  0.0753,  1.3053, -0.1028,\n",
      "         -1.2409,  0.3344, -1.0247,  0.7216, -0.1190,  2.8702,  0.3622,  1.9307,\n",
      "          0.0279, -1.6256,  0.5232, -1.2970, -1.3104,  0.3046],\n",
      "        [ 0.0227,  1.3508,  0.5581, -0.0485, -0.0194,  0.7866, -0.2855,  3.1036,\n",
      "          1.3032, -1.1621,  0.3512,  0.1232,  0.3633,  1.0291, -0.4527, -0.6809,\n",
      "         -0.5829,  1.3929, -0.8739, -0.1085,  1.7850, -1.3291,  2.2160,  0.5579,\n",
      "         -1.7158, -0.5523,  1.2403, -0.4867,  1.3974, -0.3357],\n",
      "        [ 0.8743, -2.2010, -0.5847, -0.5885, -0.9564,  0.0506,  0.1068, -0.0285,\n",
      "          0.1276, -0.2997, -0.2609, -1.1059, -1.4387,  0.9147,  1.2215, -1.6205,\n",
      "         -0.7059,  0.7516, -0.6387, -0.1229, -0.2904,  0.8357, -1.0272, -0.8320,\n",
      "          0.0861, -0.0963,  1.0795,  1.4436, -1.0763, -2.5126],\n",
      "        [ 1.6143, -0.1766, -0.5827,  1.5049, -0.2607, -0.3128, -0.4365, -0.3424,\n",
      "         -1.1624, -0.3047, -0.5121,  0.4094, -1.1650, -0.2240,  0.9086,  0.8948,\n",
      "         -0.0394, -0.0210, -0.8850, -0.2697,  1.4968,  2.3980,  0.3608,  2.8990,\n",
      "          0.9259,  0.4809,  0.6204,  0.5182,  0.4943,  1.3346],\n",
      "        [ 0.0500, -1.5307,  1.0580, -0.0952, -0.0256, -1.2355, -0.7851,  1.1269,\n",
      "         -1.9774,  0.3969,  0.4479,  0.8903,  0.5640,  1.6231,  0.8124, -0.8641,\n",
      "         -0.0595, -1.1317, -0.1431,  1.2410, -0.8248, -0.1953,  0.7213, -0.2129,\n",
      "         -0.5859,  0.1199, -0.3289,  0.7836,  0.1306, -0.6045],\n",
      "        [ 1.3463, -0.7169, -0.1675,  2.8771, -0.1836,  1.9337,  0.4198, -1.7697,\n",
      "         -1.7867,  0.9726, -0.2811, -0.0909, -0.2558,  0.0271,  0.7143, -1.5073,\n",
      "         -0.8106,  0.3257, -0.3188,  0.1627,  0.6708,  1.8927, -0.6309,  0.4710,\n",
      "          0.0928,  0.4632,  1.3058,  1.4521,  1.3959, -0.6129],\n",
      "        [-2.3273, -0.4281, -0.1495,  0.6551,  0.4892, -1.7112, -0.6234, -1.3936,\n",
      "          0.9876, -0.7416, -0.9376, -0.6311, -0.1110, -1.5460,  0.7878, -1.0992,\n",
      "          0.5328, -1.1483,  0.7772, -0.1078,  1.5774, -0.9115, -2.1092,  0.5882,\n",
      "         -0.3393,  0.5121,  0.4399, -0.9936,  2.0424, -0.9002],\n",
      "        [ 0.7293, -1.0227, -0.1653, -0.3428,  0.9152, -1.5653,  0.6921, -0.1907,\n",
      "          0.1709, -0.7579, -0.4314, -0.2646, -0.4101,  1.3839,  0.4602,  1.1660,\n",
      "         -0.9048,  0.7664,  0.0645,  1.0859, -0.0743,  0.2762, -1.6392,  0.1472,\n",
      "          0.0355,  0.3625,  0.4841,  0.3290,  1.8226,  0.7169],\n",
      "        [ 0.3110,  0.6699,  1.0949,  0.3507, -0.1873,  0.2554, -0.8926, -1.0402,\n",
      "          0.3267, -1.2695,  1.1398,  0.0642, -0.3062,  0.1736, -0.5636, -0.7673,\n",
      "          0.9416, -1.0193, -0.6424, -0.1722, -0.2227,  1.1561, -0.9863,  1.8195,\n",
      "         -0.2332,  1.2823, -1.3177,  0.8496, -0.1872,  0.1308],\n",
      "        [ 0.4856,  0.6875, -1.8234, -1.0656, -0.5358, -2.2846,  0.1837,  1.0785,\n",
      "         -0.1983, -1.8843, -0.2409,  0.4871, -1.0338, -1.7208,  0.2252,  0.4682,\n",
      "          0.3938, -1.8824,  0.9737, -0.6945, -0.3223, -1.1331, -0.1020, -0.3121,\n",
      "         -1.1440, -2.1940,  0.2419, -0.2276, -0.1000, -1.8428]]) tensor([[ 0.1174,  0.8068,  2.3262,  2.7834, -1.8946,  0.5433,  1.1542, -1.7707,\n",
      "          0.5837, -2.3188,  1.1625, -0.4075, -1.2890,  0.4736, -0.0306,  0.3414,\n",
      "          1.4569,  0.1150,  1.1375, -0.0373, -3.7484,  0.5208,  1.0894, -0.2983,\n",
      "         -0.1841, -0.7207,  0.6836, -0.3213, -0.3596,  0.3270],\n",
      "        [-0.6735,  1.1438, -1.3002,  0.9555, -1.3625,  1.5225,  1.0048, -0.1269,\n",
      "          0.8040, -0.1383, -0.2960, -0.9925, -0.0358, -0.4156,  0.1286, -1.0225,\n",
      "          0.2988,  0.1741, -1.4451, -0.8755, -1.8713,  0.6161, -0.2249, -0.2612,\n",
      "         -0.0298,  0.1738,  0.4915, -0.4530,  0.9891, -2.3225],\n",
      "        [ 0.3573, -0.1959,  0.9250, -0.3422, -0.1719,  0.4914,  0.0905, -0.7457,\n",
      "         -1.0194,  0.7152,  0.6383, -0.4931,  0.2661, -0.2840, -0.2516,  0.0975,\n",
      "          0.8270,  0.8083, -0.2363,  0.1644,  0.8750, -1.0975,  0.7323,  0.3985,\n",
      "         -1.3761, -1.6000,  0.2207, -0.6741,  0.4887,  0.9508],\n",
      "        [ 0.9256, -0.6189,  0.3823,  1.0841, -0.5785, -0.1133,  0.3990,  0.1495,\n",
      "         -0.3399, -0.4014,  0.9365, -1.4930, -0.3915,  1.1948,  0.0847, -2.2566,\n",
      "         -0.1760,  0.2564, -0.3969,  0.9997,  0.3119, -0.0074, -0.3257,  2.3560,\n",
      "          0.8767, -0.4422,  0.3095,  0.5078,  0.6233, -1.1952],\n",
      "        [ 0.0599, -0.8922, -1.4590, -0.8801, -0.4242, -1.0378,  1.0473,  0.1427,\n",
      "          1.1594,  0.0082, -1.5683, -2.6393, -1.1219, -0.5813, -0.1336, -0.0828,\n",
      "          2.0991, -0.7482, -1.4207,  1.5026,  1.4023, -1.8048, -0.2447,  0.7845,\n",
      "          1.7710,  0.4921,  0.0731,  0.9477, -1.3408,  0.8862],\n",
      "        [ 1.4013,  0.3945, -1.2497, -0.9350,  0.7442,  0.9369,  1.2684,  0.2647,\n",
      "          1.3808,  0.3957, -1.8215,  1.9934,  1.3695,  0.3327,  0.2884, -0.7545,\n",
      "          2.3327, -0.1640, -0.4336, -0.1575,  0.1044,  0.8843,  0.3991, -0.9857,\n",
      "          0.2952, -0.3573,  0.1646, -0.1906, -0.0429, -1.0565],\n",
      "        [ 0.4327,  0.0048, -1.3548, -0.2919,  0.9710, -1.2346,  1.1650,  1.3933,\n",
      "         -1.1957, -0.4690,  1.0210,  0.5475,  0.2889, -1.7118, -1.3013,  1.2256,\n",
      "          1.5144,  0.3442,  1.1810, -1.3732,  1.4765,  0.0304,  0.1298, -0.1160,\n",
      "          1.7673,  0.4996, -1.1870,  0.7127, -1.1081, -1.4002],\n",
      "        [-0.3412, -0.9620,  1.2763, -0.0690,  0.3447, -0.5258,  0.1387,  0.4863,\n",
      "          1.0107,  1.0925, -1.1933,  0.2477,  1.1339,  0.3046, -0.1635, -0.2019,\n",
      "          0.3420,  0.7317,  0.5434,  1.7662, -1.2644, -0.6877, -1.2337,  0.7028,\n",
      "          0.4259, -0.2114, -2.2158,  0.2746, -0.3729, -0.4347],\n",
      "        [-1.0698, -0.0654, -3.1752, -0.2866, -1.1055,  2.1139,  0.7690, -1.4105,\n",
      "          1.2853,  0.3602, -0.9548, -1.5847, -0.0128, -1.0992,  0.7093,  0.9510,\n",
      "         -0.9334, -0.0797, -0.4479, -0.7987, -0.4271,  0.0575, -0.5719,  1.8873,\n",
      "          0.2291, -1.0940,  0.8161,  1.5934, -0.8721, -1.3481],\n",
      "        [-1.5385,  0.7061,  0.5495,  2.7079, -0.1777, -1.5035,  0.5215, -0.6228,\n",
      "          0.1487, -0.2039,  2.6681, -0.8126,  0.1562,  0.2359,  0.6387,  0.2324,\n",
      "         -0.6369, -0.6832,  0.3727, -0.6208,  1.3708, -0.6545,  1.1296, -1.7280,\n",
      "          0.4287, -0.5969,  0.8067,  0.6371, -0.8951, -1.1871]])\n",
      "tensor(-1.5149)\n",
      "tensor(2.0503)\n",
      "tensor(-6.1642)\n",
      "tensor(7.6580)\n",
      "tensor(-5.7433)\n",
      "tensor(-0.3040)\n",
      "tensor(-2.1120)\n",
      "tensor(3.3284)\n",
      "tensor(-2.3736)\n",
      "tensor(3.5062)\n"
     ]
    }
   ],
   "source": [
    "#Data.device\n",
    "\n",
    "tempx = torch.empty([10, 30]).normal_()\n",
    "tempn = torch.empty([10, 30]).normal_()\n",
    "\n",
    "print(tempx, tempn)\n",
    "\n",
    "torch.Tensor([tempx_row.mul(tempn_row).sum() for (tempx_row, tempn_row) in zip(tempx, tempn)])\n",
    "\n",
    "for (tempx_row, tempn_row) in zip(tempx, tempn):\n",
    "    print(tempx_row.mul(tempn_row).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9057, -1.4018,  0.5746],\n",
      "        [ 0.4654, -1.9444,  0.2010]])\n",
      "tensor([[ 0.0267, -0.6325,  0.6092],\n",
      "        [ 1.2589, -1.3695, -1.7831]])\n",
      "\n",
      "\n",
      "tensor([[-0.0242,  0.8866,  0.3501],\n",
      "        [ 0.5859,  2.6629, -0.3584]])\n",
      "tensor([[-0.0242,  0.8866,  0.3501],\n",
      "        [ 0.5859,  2.6629, -0.3584]])\n",
      "tensor([[-0.0242,  0.8866,  0.3501],\n",
      "        [ 0.5859,  2.6629, -0.3584]])\n"
     ]
    }
   ],
   "source": [
    "tempx = torch.empty([2, 3]).normal_()\n",
    "tempn = torch.empty([2, 3]).normal_()\n",
    "\n",
    "print(tempx)\n",
    "print(tempn)\n",
    "print('\\n')\n",
    "\n",
    "print(torch.mul(tempx, tempn))\n",
    "print(tempx * tempn)\n",
    "print(np.multiply(tempx, tempn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.9926, -2.6195, -0.8006, -7.9129,  1.4417,  3.0230,  3.7683, -0.9516,\n",
      "         4.1613, 13.2766])\n",
      "tensor([-3.9926, -2.6195, -0.8006, -7.9129,  1.4417,  3.0230,  3.7683, -0.9516,\n",
      "         4.1613, 13.2766])\n"
     ]
    }
   ],
   "source": [
    "print(torch.diagonal(torch.mm(tempx, tempn.transpose(1, 0))))\n",
    "print((tempx * tempn).sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Files for Process: W+Z, with new physics Parameters: ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Nuisance_Data/ChP_pt300_gw9e-3_nuisance.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., 0.009}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Nuisance_Events/ChP_pt300_gw9e-3_nuisance.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "No SM files input. Skipping loading SM files.\n",
      "No SM files input. Skipping loading SM data.\n",
      "No SM files input. Simply assign BSM data.\n",
      "\n",
      "Loaded BSM Files:\n",
      "['Gphi[TeV**-2]', 'GW[TeV**-2]']                   #Data    XS[pb](avg.w)\n",
      "-----------------------------------------------  -------  ---------------\n",
      "tensor([[0.0000, 0.0090]], dtype=torch.float64)     1000         0.737236\n",
      "####\n",
      "Anlges at position [3, 5] have been converted to Sin and Cos and put at the last columns of the Data.\n",
      "####\n",
      "Initializing Preprocesses Variables\n",
      "Training epoch 2 (took 0.01 sec, time left 0:00:01.988488 sec) loss 0.07638957\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPgw, (500 epochs Seed994), 2 epoch.pth\n",
      "Training epoch 5 (took 0.03 sec, time left 0:00:03.217206 sec) loss 0.04789554\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPgw, (500 epochs Seed994), 5 epoch.pth\n",
      "Training epoch 10 (took 0.03 sec, time left 0:00:03.296139 sec) loss 0.02706459\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPgw, (500 epochs Seed994), 10 epoch.pth\n",
      "Training epoch 50 (took 0.25 sec, time left 0:00:02.820953 sec) loss 0.00153395\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPgw, (500 epochs Seed994), 50 epoch.pth\n",
      "Training epoch 100 (took 0.31 sec, time left 0:00:02.474013 sec) loss 0.00031541\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPgw, (500 epochs Seed994), 100 epoch.pth\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/PDFLinearClassifier/TrainedModels/PDF_ChPgw, (500 epochs Seed994), Final.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OurLinearModel(\n",
       "  (LinearLayers): ModuleList(\n",
       "    (0): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Linear(in_features=32, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFolder = '/data3/WZ_new_project/h5/Ideal_Nuisance_Data/'\n",
    "\n",
    "td = OurTrainingData([],\n",
    "                     [DataFolder + 'ChP_pt300_gw9e-3_nuisance.h5',],\n",
    "                     process = 'W+Z', parameters =['Gphi[TeV**-2]', 'GW[TeV**-2]'], \n",
    "                     SMNLimits=int(3e6),\n",
    "                     BSMNLimits=int(5e5))\n",
    "\n",
    "NumEpochs = int(5e2)\n",
    "\n",
    "td.Data = td.Data[:, :7]\n",
    "td.CurateAngles([3, 5])\n",
    "\n",
    "Data, ParVal, Labels, Weights, PDFWeights = td.Data, td.ParVal, td.Labels, td.Weights, td.PDFWeights\n",
    "Data, ParVal, Labels, Weights, PDFWeights = Data.float(), ParVal.float(), Labels.float(), Weights.float(), PDFWeights.float()\n",
    "\n",
    "\n",
    "MD = OurLinearModel(NumberOfNuisanceParameters=PDFWeights.size(1), AR=[9,32,32,32,30])\n",
    "\n",
    "MD.InitPreprocess(Data, PDFWeights)\n",
    "\n",
    "OT = OurTrainer(NumEpochs = NumEpochs)\n",
    "OT.SetSaveAfterEpochs([2, 5, 10, 50, 100])\n",
    "\n",
    "random_seed = torch.randint(0, 1339, (1,)).item()\n",
    "OT.Train(MD, Data = Data, PDFWeights = PDFWeights, Labels=Labels, Weights= Weights, bs = 100000,\n",
    "        Name = 'PDF_ChPgw, (%d epochs Seed%d), '%(NumEpochs, random_seed), Folder = os.getcwd()+'/TrainedModels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=9, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for Layer in MD.LinearLayers:\n",
    "    print(Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NuisanceRatio = torch.ones(Data.size(0))\n",
    "NuisanceRatio = torch.ones([4, 1])\n",
    "PDFWeight = PDFWeights[:4, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4793.0493,     0.0000,  6951.7139],\n",
       "        [ 3610.9492,     0.0000,  5242.6865],\n",
       "        [ 4999.2144,     0.0000,  7250.1309],\n",
       "        [11534.2334,     0.0000, 16717.3340]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Data[:4]\n",
    "for i in range(len(MD.Architecture)-1):\n",
    "    x = MD.LinearLayers[i](x)\n",
    "    x = MD.ActivationFunction(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3]), torch.Size([4, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(), PDFWeight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4793.0493,     0.0000,  6951.7139],\n",
       "        [ 3610.9492,     0.0000,  5242.6865],\n",
       "        [ 4999.2144,     0.0000,  7250.1309],\n",
       "        [11534.2334,     0.0000, 16717.3340]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.1222e-03, -1.5035e-02,  7.0959e-05],\n",
       "        [ 5.3524e-03, -1.5267e-02, -1.8560e-05],\n",
       "        [ 7.4220e-03, -1.4974e-02,  9.0152e-05],\n",
       "        [ 1.5231e-02, -1.2172e-02,  6.6291e-04]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDFWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 34.6304,  19.2299,  37.7579, 186.7559], grad_fn=<DiagonalBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diagonal(torch.mm(x, PDFWeight.transpose(1, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "NuisanceRatio += torch.mul(PDFWeight, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NuisanceRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0002],\n",
       "        [0.0002],\n",
       "        [0.0002]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDFWeights[:3, 29:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 30])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDFWeights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2229],\n",
       "        [0.6801],\n",
       "        [2.5537]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = PDFWeight/PDFWeight.std(0)\n",
    "temp += 1.\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
